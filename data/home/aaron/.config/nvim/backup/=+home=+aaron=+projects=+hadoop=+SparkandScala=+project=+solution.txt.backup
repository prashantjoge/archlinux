#######################################################
# This solution was created using Spark Shell        ##
# on a local computer because I also wanted to learn ##
# how to configure the HDFS ecosystem                ##
#######################################################


# Load data into HDFS
hdfs dfs -copyFromLocal bank-full.csv

# Load Data into RDD (Resilient Distributed Data)
val data = sc.textFile("bank-full.csv")

# Console Output
data: org.apache.spark.rdd.RDD[String] = bank-full.csv MapPartitionsRDD[174] at textFile at <console>:24

# Load Data in DataFrame
 val mydf = spark.read.option("delimiter",";").option("header","true").format("csv").load("bank-full.csv")

# Console Output
mydf: org.apache.spark.sql.DataFrame = [age: string, job: string ... 15 more fields]

# Show Schema

mydf.printSchema

#Output
root
 |-- age: string (nullable = true)
 |-- job: string (nullable = true)
 |-- marital: string (nullable = true)
 |-- education: string (nullable = true)
 |-- default: string (nullable = true)
 |-- balance: string (nullable = true)
 |-- housing: string (nullable = true)
 |-- loan: string (nullable = true)
 |-- contact: string (nullable = true)
 |-- day: string (nullable = true)
 |-- month: string (nullable = true)
 |-- duration: string (nullable = true)
 |-- campaign: string (nullable = true)
 |-- pdays: string (nullable = true)
 |-- previous: string (nullable = true)
 |-- poutcome: string (nullable = true)
 |-- y: string (nullable = true)

#########################################
# Display the head ######################
#########################################
mydf.head

# Output
res38: org.apache.spark.sql.Row = [58,management,married,tertiary,no,2143,yes,no,unknown,5,may,261,1,-1,0,unknown,no]

mydf.first

# Output
res39: org.apache.spark.sql.Row = [58,management,married,tertiary,no,2143,yes,no,unknown,5,may,261,1,-1,0,unknown,no]

#########################################
# Register temporary table ##############
#########################################
mydf.createOrReplaceTempView("bankData")

##########################################
# Marketing Success ######################
##########################################
val success_rate = (mydf.filter($"y" === "\"yes\"").count).toDouble / (mydf.count).toDouble

# Output
success_rate: Double = 0.0

sql("select (count(y)/ (select count(*) from bankdata))*100 as SuccessRate from bankdata where y='yes' " ).show

+------------------+
|       SuccessRate|
+------------------+
|11.698480458295547|
+------------------+

#########################################
# Age Statistics ########################
#########################################
sql("select max(age) as MaxAge, min(age) as MinAge, avg(age) as avgAge , percentile(age, 0.50) as percentile from bankdata").show

# Output
+------+------+-----------------+----------+
|MaxAge|MinAge|           avgAge|percentile|
+------+------+-----------------+----------+
|    95|    18|40.93621021432837|      39.0|
+------+------+-----------------+----------+

##########################################
# Mean and Median Balance ################
##########################################
sql("SELECT avg(balance) as mean ,percentile_approx(balance, 0.5) as median  FROM bankdata").show

# Output
+------------------+------+
|              mean|median|
+------------------+------+
|1362.2720576850766| 448.0|
+------------------+------+

#################################################
# Average age of subscribers vs. Non-subscribers#
#################################################

mydf.groupBy("y").agg(avg($"age")).show

# Output
+---+------------------+
|  y|          avg(age)|
+---+------------------+
| no| 40.83898602274435|
|yes|41.670069956513515|
+---+------------------+

sql("SELECT y,avg(age) as avgAge FROM bankdata group by y").show

# Output
+---+------------------+
|  y|            avgAge|
+---+------------------+
| no| 40.83898602274435|
|yes|41.670069956513515|
+---+------------------+

################################################
# Count of subscribers vs. Non-Subscribers #####
################################################
mydf.groupBy("y").agg(count($"marital")).show

# Output
+---+--------------+
|  y|count(marital)|
+---+--------------+
| no|         39922|
|yes|          5289|
+---+--------------+

 sql("SELECT y,count(age) as count FROM bankdata group by y").show

 # Output
 +---+-----+
|  y|count|
+---+-----+
| no|39922|
|yes| 5289|
+---+-----+

#################################################
# Count based on Marital status and subscribers #
#################################################
mydf.groupBy("marital","y").count.orderBy($"marital".desc).show

# Output
+--------+---+-----+                                                            
| marital|  y|count|
+--------+---+-----+
|  single| no|10878|
|  single|yes| 1912|
| married|yes| 2755|
| married| no|24459|
|divorced|yes|  622|
|divorced| no| 4585|
+--------+---+-----+
sql("SELECT marital , y, count(age) as count FROM bankdata group by y, marital order by count(age) asc").show

# Output
+--------+---+-----+                                                            
| marital|  y|count|
+--------+---+-----+
|divorced|yes|  622|
|  single|yes| 1912|
| married|yes| 2755|
|divorced| no| 4585|
|  single| no|10878|
| married| no|24459|
+--------+---+-----+

############################################################
# Count of respondents based on age & subscription Status ##
############################################################
mydf.groupBy("age","y").count.orderBy($"count".desc).show

# Output
+---+---+-----+                                                                 
|age|  y|count|
+---+---+-----+
| 32| no| 1864|
| 31| no| 1790|
| 33| no| 1762|
| 34| no| 1732|
| 35| no| 1685|
| 36| no| 1611|
| 30| no| 1540|
| 37| no| 1526|
| 39| no| 1344|
| 38| no| 1322|
| 40| no| 1239|
| 41| no| 1171|
| 42| no| 1131|
| 45| no| 1110|
| 43| no| 1058|
| 46| no| 1057|
| 44| no| 1043|
| 29| no| 1014|
| 47| no|  975|
| 48| no|  915|
+---+---+-----+
only showing top 20 rows

 sql("SELECT age , y, count(age) as count FROM bankdata group by y, age order by count(age) desc").show

# Output
+---+---+-----+                                                                 
|age|  y|count|
+---+---+-----+
| 32| no| 1864|
| 31| no| 1790|
| 33| no| 1762|
| 34| no| 1732|
| 35| no| 1685|
| 36| no| 1611|
| 30| no| 1540|
| 37| no| 1526|
| 39| no| 1344|
| 38| no| 1322|
| 40| no| 1239|
| 41| no| 1171|
| 42| no| 1131|
| 45| no| 1110|
| 43| no| 1058|
| 46| no| 1057|
| 44| no| 1043|
| 29| no| 1014|
| 47| no|  975|
| 48| no|  915|
+---+---+-----+
only showing top 20 rows

##########################################################
# Count or respondents who subscribed based on an age ####
# bracket.                                            ####
# < 25 == young										  ####
# > 60 == Old										  ####
# > 25 & < 60 == Mid_Age							  ####
##########################################################

val df_new = mydf.withColumn("age_cat", when($"age" < 25 , "young").otherwise( when    ($"age" > 60 , "old").otherwise("mid_age")  ))

# Output
df_new: org.apache.spark.sql.DataFrame = [age: string, job: string ... 16 more fields]

df_new.groupBy("age_cat","y").count.show()

# Output
+-------+---+-----+
|age_cat|  y|count|
+-------+---+-----+
|mid_age| no|38634|
|mid_age|yes| 4580|
|  young| no|  602|
|    old|yes|  502|
|    old| no|  686|
|  young|yes|  207|
+-------+---+-----+

df_new.where($"y"==="yes").groupBy("age_cat").count.show()
 +-------+-----+
|age_cat|count|
+-------+-----+
|    old|  502|
|  young|  207|
|mid_age| 4580|
+-------+-----+ 


sql("select 'young' , count(*) as total from bankdata  where y ='yes' and age < 25  union select 'mid', count(*) as total from bankdata where y='yes' and age>=25 and age <=60 union select 'old', count(*) as total from bankdata where y='yes' and age >=60").show
+-----+--------+
|young|count(1)|
+-----+--------+
|young|     207|
|  mid|    4762|
|  old|     341|
+-----+--------+
