#######################################################
# This solution was created using Spark Shell        ##
# on a local computer because I also wanted to learn ##
# how to configure the HDFS ecosystem                ##
#######################################################


# Load data into HDFS
hdfs dfs -copyFromLocal bank-full.csv

# Load Data into RDD (Resilient Distributed Data)
val data = sc.textFile("bank-full.csv")

# Console Output
data: org.apache.spark.rdd.RDD[String] = bank-full.csv MapPartitionsRDD[174] at textFile at <console>:24

# Load Data in DataFrame
 val mydf = spark.read.option("delimiter",";").option("header","true").format("csv").load("bank-full.csv")

# Console Output
mydf: org.apache.spark.sql.DataFrame = [age: string, job: string ... 15 more fields]

# Show Schema

mydf.printSchema

#Output
root
 |-- age: string (nullable = true)
 |-- job: string (nullable = true)
 |-- marital: string (nullable = true)
 |-- education: string (nullable = true)
 |-- default: string (nullable = true)
 |-- balance: string (nullable = true)
 |-- housing: string (nullable = true)
 |-- loan: string (nullable = true)
 |-- contact: string (nullable = true)
 |-- day: string (nullable = true)
 |-- month: string (nullable = true)
 |-- duration: string (nullable = true)
 |-- campaign: string (nullable = true)
 |-- pdays: string (nullable = true)
 |-- previous: string (nullable = true)
 |-- poutcome: string (nullable = true)
 |-- y: string (nullable = true)

#########################################
# Display the head ######################
#########################################
mydf.head

# Output
res38: org.apache.spark.sql.Row = [58,management,married,tertiary,no,2143,yes,no,unknown,5,may,261,1,-1,0,unknown,no]

mydf.first

# Output
res39: org.apache.spark.sql.Row = [58,management,married,tertiary,no,2143,yes,no,unknown,5,may,261,1,-1,0,unknown,no]

#########################################
# Register temporary table ##############
#########################################
mydf.createOrReplaceTempView("bankData")

##########################################
# Marketing Success ######################
##########################################
val success_rate = (mydf.filter($"y" === "\"yes\"").count).toDouble / (mydf.count).toDouble

# Output
success_rate: Double = 0.0

sql("select (count(y)/ (select count(*) from bankdata))*100 as SuccessRate from bankdata where y='yes' " ).show

+------------------+
|       SuccessRate|
+------------------+
|11.698480458295547|
+------------------+

#########################################
# Age Statistics ########################
#########################################
sql("select max(age) as MaxAge, min(age) as MinAge, avg(age) as avgAge , percentile(age, 0.50) as percentile from bankdata").show

# Output
+------+------+-----------------+----------+
|MaxAge|MinAge|           avgAge|percentile|
+------+------+-----------------+----------+
|    95|    18|40.93621021432837|      39.0|
+------+------+-----------------+----------+

##########################################
# Mean and Median Balance ################
##########################################
sql("SELECT avg(balance) as mean ,percentile_approx(balance, 0.5) as median  FROM bankdata").show

# Output
+------------------+------+
|              mean|median|
+------------------+------+
|1362.2720576850766| 448.0|
+------------------+------+

#################################################
# Average age of subscribers vs. Non subscribers#
#################################################

mydf.groupBy("y").agg(avg($"age")).show

# Output
+---+------------------+
|  y|          avg(age)|
+---+------------------+
| no| 40.83898602274435|
|yes|41.670069956513515|
+---+------------------+

sql("SELECT y,avg(age) as avgAge FROM bankdata group by y").show

# Output
+---+------------------+
|  y|            avgAge|
+---+------------------+
| no| 40.83898602274435|
|yes|41.670069956513515|
+---+------------------+

