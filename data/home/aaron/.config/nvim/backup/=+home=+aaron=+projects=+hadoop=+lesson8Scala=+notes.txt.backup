
val df = spark.sqlContext.read.format("csv").option("header", "true").option("inferSchema", "true").load("lesson8/7_companies_case_study.csv");

df.dtypes;
df.columns;
df.count;
df.show;
df.schema;

df.filter(df("name")==="amazon").show(false);
df.filter(df("year founded") < "1980").show(true);
df.groupBy("name","total employee estimate").agg(max("total employee estimate") as("maxEmp")).orderBy($"maxEmp".desc).show(5);

 df.groupBy("industry").agg(count("name") as ("cmpny_Count")).orderBy($"cmpny_Count".desc).show(5);

df.createTempView("Companies");
