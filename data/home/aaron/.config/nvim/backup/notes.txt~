# Hadoop config files
# Located in /usr/local/hadoop/etc/hadoop

1. hadoop-env.sh
2. core-site.xml
// hdfs path and location of name node ex. <value>hdfs://wormwood:9000</value>
3. hdfs-site.xml
4. mapreduce-site.xml
5. yarn-site.xml
6. slaves now workers (on master)
7. Masters (on master)

Fs.defaultFS = hdfs://wormwood:9000
Name Node: wormwood:50070
secondary NameNode : m3:50090
resource manager : wormwood:9001
resource tracker : wormwood:8031
mapreduce wormwood:9101
mapreduce.jobhistory.address: Default port is 10020.
mapreduce.jobhistory.webapp.address	MapReduce JobHistory Server Web UI host:port	Default port is 19888.

// example of copying files from one server to another
scp slaves  hduser@m1:/usr/local/hadoop/etc/hadoop

/usr/local/zookeeper/bin/./zkServer.sh start
to verify zookeeper is working run ./zkCli.sh -server wormwood:2181

start-dfs.sh
start-yarn.sh
mapred --daemon start historyserver

mapred --daemon stop historyserver
hdfs dfsadmin -refreshNodes
hdfs dfsadmin -report
hdfs balancer

High availability of Zookeper.

Start on all zookeeper nodes  (wormwood,m1,m2 )
/usr/local/zookeeper/bin/./zkServer.sh start

/usr/local/zookeeper/bin/./zkServer.sh stop
High availability of resource manager
start only on the main node
start-yarn.sh


WITH High availability on Name Node
1 DataNode
2 NodeManager
3 DFSZKFailoverController
4 JournalNode
5 NameNode
6 ResourceManager
7 JobHistoryServer
8 QuorumPeerMain

M1
13601 JournalNode
13491 DataNode
14181 Jps
13385 NameNode
13982 NodeManager

M2
12177 DataNode
12306 JournalNode
12693 NodeManager
12892 Jps
12079 NameNode

M3
9980 DataNode
10108 NodeManager
# Secondary name node missing
https://stackoverflow.com/questions/33494697/secondary-namenode-usage-and-high-availability-in-hadoop-2-x
Web Addresses
http://wormwood:19888/jobhistory
http://wormwood:9870/dfshealth.html
http://wormwood:9864/datanode.html
http://wormwood:9864/datanode.html
http://wormwood:8480/

----------------------------
FIX for under replication

hdfs dfs -setrep -w 3 /

Rule of thump: # of replicas should be equal to the number of data nodes
--------------------------
Journal node failures

https://www.developerscloset.com/?p=1144

## format namenode for HA (start afresh)
hdfs --daemon start journalnode ##on all nodes
hdfs namenode -format
if the journalnodes are in an inconsistent state with error message that it is in an inconsistent state delete contents of journal node directory on all namenodes
reboot the machine, The Vms may cause this
hdfs namenode -bootstrapStandby # Start the master namenode before you run this

#format zookeeper
hdfs zkfc -formatZK -force

To list the contents of the cluster
hdfs dfs -ls hdfs://mycluster (this works for the first three nodes because they are part of the cluster)
 hadoop fs -ls hdfs:/// ( because the fourth data node is not part of the cluster)



