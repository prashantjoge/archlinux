# Read the data
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import pandas as pd
train_data = pd.read_csv('~/projects/datasets/iowa/train.csv')
test_data = pd.read_csv('~/projects/datasets/iowa/test.csv')

# drop houses where target data is missing, remember its axis 0 so columns are not dropped; just the rows are dropped
# print(train_data)
train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)
# print(train_data)
target = train_data.SalePrice
# Since missing values isn't the focus of this tutorial, we use the simplest
# possible approach, which drops these columns.
# For more detail (and a better approach) to missing values, see
# https://www.kaggle.com/dansbecker/handling-missing-values
cols_with_missing = [
    col for col in train_data.columns if train_data[col].isnull().any()]

# cols_with_data = [
#    col for col in train_data.columns if train_data[col].notnull().any()]
# print(cols_with_missing)
# print(cols_with_data)
# drop ID and SalePrice Columns, Axis=1
candidate_train_predictors = train_data.drop(
    ['Id', 'SalePrice'] + cols_with_missing, axis=1)
# print(candidate_train_predictors)
# drop missing columns
candidate_test_predictors = test_data.drop(['Id'] + cols_with_missing, axis=1)
# "cardinality" means the number of unique values in a column.
# We use it as our only way to select categorical columns here. This is convenient, though
# a little arbitrary.
low_cardinality_cols = [cname for cname in candidate_train_predictors.columns if candidate_train_predictors[cname].nunique(
) < 10 and candidate_train_predictors[cname].dtype == "object"]
numeric_cols = [cname for cname in candidate_train_predictors.columns if candidate_train_predictors[cname].dtype in [
    'int64', 'float64']]
my_cols = low_cardinality_cols + numeric_cols
# print(my_cols)
train_predictors = candidate_train_predictors[my_cols]
test_predictors = candidate_test_predictors[my_cols]
train_predictors.info()
test_predictors.info()
one_hot_encoded_test_predictors = pd.get_dummies(test_predictors)
# print(train_predictors.dtypes.sample(20))
one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)
# print(one_hot_encoded_training_predictors)
final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,
                                                                    join='left',
                                                                    axis=1)


def get_mae(X, y):
    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention
    return -1 * cross_val_score(RandomForestRegressor(50), X, y, scoring='neg_mean_absolute_error').mean()


predictors_without_categoricals = train_predictors.select_dtypes(exclude=[
                                                                 'object'])
mae_without_categoricals = get_mae(predictors_without_categoricals, target)
mae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, target)
print('Mean Absolute Error when Dropping Categoricals: ' +
      str(int(mae_without_categoricals)))
print('Mean Abslute Error with One-Hot Encoding: ' +
      str(int(mae_one_hot_encoded)))
